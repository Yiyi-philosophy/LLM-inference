{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Total Latency (s)  Total Throughput (token/s)  Peak GPU Mem (GB)\n",
      "0              2.158                     474.599              3.699\n"
     ]
    }
   ],
   "source": [
    "# 打开日志文件\n",
    "with open('fo-1.3b-gbs8-ngbs4-prompt128-gen32-percent-100-0-100-0-100-0-gpu-cache.log', 'r') as file:\n",
    "    log_data = file.read()\n",
    "\n",
    "# 使用正则表达式提取信息\n",
    "total_latency = re.search(r'total latency: ([\\d.]+) s', log_data).group(1)\n",
    "total_throughput = re.search(r'total throughput: ([\\d.]+) token/s', log_data).group(1)\n",
    "peak_gpu_mem = re.search(r'peak gpu mem: ([\\d.]+) GB', log_data).group(1)\n",
    "\n",
    "# 创建一个 Pandas DataFrame\n",
    "data = {\n",
    "    'Total Latency (s)': [float(total_latency)],\n",
    "    'Total Throughput (token/s)': [float(total_throughput)],\n",
    "    'Peak GPU Mem (GB)': [float(peak_gpu_mem)]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 打印 DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Num Batches Prompt Len  Total Latency (s)  Total Throughput (token/s)  \\\n",
      "0            4        128              2.158                     474.599   \n",
      "1            4        256              2.320                     441.424   \n",
      "2            4        512              2.626                     389.879   \n",
      "3            4       1024              3.524                     290.593   \n",
      "4            8        128              4.321                     473.985   \n",
      "5            8        256              4.647                     440.707   \n",
      "6            8        512              5.324                     384.683   \n",
      "7            8       1024              7.092                     288.789   \n",
      "8           16        128              8.692                     471.235   \n",
      "9           16        256              9.390                     436.231   \n",
      "10          16        512             10.633                     385.228   \n",
      "11          16       1024             14.248                     287.482   \n",
      "12          32        128             17.382                     471.291   \n",
      "13          32        256             18.790                     435.974   \n",
      "14          32        512             21.467                     381.616   \n",
      "15          32       1024              0.000                       0.000   \n",
      "\n",
      "    Peak GPU Mem (GB)  \n",
      "0               3.699  \n",
      "1               4.555  \n",
      "2               6.278  \n",
      "3              10.153  \n",
      "4               4.652  \n",
      "5               6.268  \n",
      "6               9.522  \n",
      "7              16.460  \n",
      "8               6.559  \n",
      "9               9.694  \n",
      "10             16.011  \n",
      "11             29.073  \n",
      "12             10.371  \n",
      "13             16.546  \n",
      "14             28.987  \n",
      "15              0.000  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Create an empty list to store the data\n",
    "data_list = []\n",
    "\n",
    "# Define ngbs values and prompt values\n",
    "ngbs_values = ['4', '8', '16', '32']\n",
    "prompt_values = ['128', '256', '512', '1024']\n",
    "\n",
    "# Loop through each ngbs and prompt value\n",
    "for ngbs in ngbs_values:\n",
    "    for prompt in prompt_values:\n",
    "        # Construct the filename based on ngbs and prompt values\n",
    "        filename = f\"fo-1.3b-gbs8-ngbs{ngbs}-prompt{prompt}-gen32-percent-100-0-100-0-100-0-gpu-cache.log\"  # Replace with your actual filename format\n",
    "        \n",
    "        # Open the log file\n",
    "        with open(filename, 'r') as file:\n",
    "            log_data = file.read()\n",
    "        \n",
    "        # Use regular expressions to extract information\n",
    "        total_latency = re.search(r'total latency: ([\\d.]+) s', log_data).group(1)\n",
    "        total_throughput = re.search(r'total throughput: ([\\d.]+) token/s', log_data).group(1)\n",
    "        peak_gpu_mem = re.search(r'peak gpu mem: ([\\d.]+) GB', log_data).group(1)\n",
    "\n",
    "        # Append the extracted information to the data list as a dictionary\n",
    "        data_list.append({'Num Batches': ngbs, \n",
    "                          'Prompt Len': prompt,\n",
    "                          'Total Latency (s)': float(total_latency),\n",
    "                          'Total Throughput (token/s)': float(total_throughput),\n",
    "                          'Peak GPU Mem (GB)': float(peak_gpu_mem)})\n",
    "\n",
    "# Create a DataFrame from the list of dictionaries\n",
    "df = pd.DataFrame(data_list)\n",
    "\n",
    "# Print the entire DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('df.xlsx', sheet_name='df_prom')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyllama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
