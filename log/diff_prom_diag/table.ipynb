{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Total Latency (s)  Total Throughput (token/s)  Peak GPU Mem (GB)\n",
      "0              1.246                      822.02              3.525\n"
     ]
    }
   ],
   "source": [
    "# 打开日志文件\n",
    "with open('fo-1.3b-gbs8-ngbs4-prompt128-gen32-percent-100-0-100-0-100-0-gpu-cache.log', 'r') as file:\n",
    "    log_data = file.read()\n",
    "\n",
    "# 使用正则表达式提取信息\n",
    "total_latency = re.search(r'total latency: ([\\d.]+) s', log_data).group(1)\n",
    "total_throughput = re.search(r'total throughput: ([\\d.]+) token/s', log_data).group(1)\n",
    "peak_gpu_mem = re.search(r'peak gpu mem: ([\\d.]+) GB', log_data).group(1)\n",
    "\n",
    "# 创建一个 Pandas DataFrame\n",
    "data = {\n",
    "    'Total Latency (s)': [float(total_latency)],\n",
    "    'Total Throughput (token/s)': [float(total_throughput)],\n",
    "    'Peak GPU Mem (GB)': [float(peak_gpu_mem)]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 打印 DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Num Batches Prompt Len  Total Latency (s)  Total Throughput (token/s)  \\\n",
      "0            4        128              1.246                     822.020   \n",
      "1            4        256              1.515                     675.800   \n",
      "2            4        512              2.069                     494.897   \n",
      "3            4       1024              3.555                     288.077   \n",
      "4            8        128              2.295                     892.348   \n",
      "5            8        256              2.724                     751.873   \n",
      "6            8        512              3.615                     566.580   \n",
      "7            8       1024              6.025                     339.892   \n",
      "8           16        128              4.585                     893.311   \n",
      "9           16        256              5.386                     760.542   \n",
      "10          16        512              6.881                     595.280   \n",
      "11          16       1024             11.101                     368.981   \n",
      "12          32        128              8.812                     929.688   \n",
      "13          32        256             10.311                     794.502   \n",
      "14          32        512             13.253                     618.147   \n",
      "15          32       1024              0.000                       0.000   \n",
      "\n",
      "    Peak GPU Mem (GB)  \n",
      "0               3.525  \n",
      "1               4.378  \n",
      "2               6.086  \n",
      "3               9.930  \n",
      "4               4.315  \n",
      "5               5.933  \n",
      "6               9.172  \n",
      "7              16.078  \n",
      "8               5.884  \n",
      "9               9.034  \n",
      "10             15.335  \n",
      "11             28.366  \n",
      "12              9.110  \n",
      "13             15.323  \n",
      "14             27.749  \n",
      "15              0.000  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Create an empty list to store the data\n",
    "data_list = []\n",
    "\n",
    "# Define ngbs values and prompt values\n",
    "ngbs_values = ['4', '8', '16', '32']\n",
    "prompt_values = ['128', '256', '512', '1024']\n",
    "\n",
    "# Loop through each ngbs and prompt value\n",
    "for ngbs in ngbs_values:\n",
    "    for prompt in prompt_values:\n",
    "        # Construct the filename based on ngbs and prompt values\n",
    "        filename = f\"fo-1.3b-gbs8-ngbs{ngbs}-prompt{prompt}-gen32-percent-100-0-100-0-100-0-gpu-cache.log\"  # Replace with your actual filename format\n",
    "        \n",
    "        # Open the log file\n",
    "        with open(filename, 'r') as file:\n",
    "            log_data = file.read()\n",
    "        \n",
    "        # Use regular expressions to extract information\n",
    "        total_latency = re.search(r'total latency: ([\\d.]+) s', log_data).group(1)\n",
    "        total_throughput = re.search(r'total throughput: ([\\d.]+) token/s', log_data).group(1)\n",
    "        peak_gpu_mem = re.search(r'peak gpu mem: ([\\d.]+) GB', log_data).group(1)\n",
    "\n",
    "        # Append the extracted information to the data list as a dictionary\n",
    "        data_list.append({'Num Batches': ngbs, \n",
    "                          'Prompt Len': prompt,\n",
    "                          'Total Latency (s)': float(total_latency),\n",
    "                          'Total Throughput (token/s)': float(total_throughput),\n",
    "                          'Peak GPU Mem (GB)': float(peak_gpu_mem)})\n",
    "\n",
    "# Create a DataFrame from the list of dictionaries\n",
    "df = pd.DataFrame(data_list)\n",
    "\n",
    "# Print the entire DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('df_diag.xlsx', sheet_name='df_prom')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyllama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
